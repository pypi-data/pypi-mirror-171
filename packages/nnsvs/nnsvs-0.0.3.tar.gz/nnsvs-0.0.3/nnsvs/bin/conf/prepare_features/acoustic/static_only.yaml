enabled: true
question_path:
wav_dir: data/acoustic/wav
label_dir: data/acoustic/label_phone_align

sample_rate: 48000

subphone_features: coarse_coding

# kiritan
# min 174.61411571650194
# max 659.2551138257398
f0_floor: null
f0_ceil: null

use_harvest: true
d4c_threshold: 0.15

frame_period: 5 # ms
mgc_order: 59

# windows to compute delta and delta-delta features
# set 1 to disable
num_windows: 1

# Stream-wise flags to enable/disable dynamic features
# (mgc, lf0, vuv, bap)
dynamic_features_flags: [False, False, False, False]

# Use relative f0 modeling.
relative_f0: true

interp_unvoiced_aperiodicity: true

# Vibrato mode (https://arxiv.org/abs/2108.02776)
# 1) none -> no vibrato modeling
#   The output features will include 4 streams: [mgc, lf0, vuv, bap]
# 2) sine -> sine vibrato modeling.
#   Three-dim features composed of two streams (vib params and vibrato flag) are added.
#   The output features will include 6 streams: [mgc, lf0, vuv, bap, vib, vib_flags]
# 3) diff -> diff-based vibrato modeling.
#   One-dim differential F0 is added.
#   The output features will include 5 streams: [mgc, lf0, vuv, bap, vib]
# NOTE: you must be careful about the dimension of the acoustic features.
# For example, if you use sine-based vibrato modeling (w/ dynamic features),
# you'd need to increase 2*num_windows + 1 for the `out_dim` of the acoustic model.
vibrato_mode: none

# Parameter trajectory smoothing
# Ref: The NAIST Text-to-Speech System for the Blizzard Challenge 2015
trajectory_smoothing: false
trajectory_smoothing_cutoff: 50

# Correct V/UV based on the musical score.
# This is to prevent unwanted F0 estimation failures on silence regions.
correct_vuv: false

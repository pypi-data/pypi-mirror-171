# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['gcloud', 'gcloud.rest', 'gcloud.rest.pubsub']

package_data = \
{'': ['*']}

install_requires = \
['gcloud-rest-auth>=3.3.0,<5.0.0']

setup_kwargs = {
    'name': 'gcloud-rest-pubsub',
    'version': '5.1.1',
    'description': 'Python Client for Google Cloud Pub/Sub',
    'long_description': "(Asyncio OR Threadsafe) Python Client for Google Cloud Pub/Sub\n==============================================================\n\n    This is a shared codebase for ``gcloud-rest-pubsub`` and\n    ``gcloud-rest-pubsub``\n\n|pypi| |pythons-aio| |pythons-rest|\n\nInstallation\n------------\n\n.. code-block:: console\n\n    $ pip install --upgrade gcloud-{aio,rest}-pubsub\n\nUsage\n-----\n\nSubscriber\n~~~~~~~~~~\n\n``gcloud-{aio,rest}-pubsub`` provides ``SubscriberClient``\nas an interface to call pubsub's HTTP API:\n\n.. code-block:: python\n\n    from gcloud.rest.pubsub import SubscriberClient\n    from gcloud.rest.pubsub import SubscriberMessage\n\n    client = SubscriberClient()\n    # create subscription\n    await client.create_subscription(\n        'projects/<project_name>/subscriptions/<subscription_name>',\n        'projects/<project_name>/topics/<topic_name>')\n\n    # pull messages\n    messages: List[SubscriberMessage] = await client.pull(\n        'projects/<project_name>/subscriptions/<subscription_name>',\n        max_messages=10)\n\n\nThere's also ``gcloud.rest.pubsub.subscribe`` helper function you can use to\nsetup a pubsub processing pipeline. It is built with ``asyncio`` and thus only\navailable in ``gcloud-rest-pubsub`` package. The usage is fairly simple:\n\n.. code-block:: python\n\n    from gcloud.rest.pubsub import SubscriberClient\n    from gcloud.rest.pubsub import subscribe\n\n    subscriber_client = SubscriberClient()\n\n    async def handler(message):\n        return\n\n    await subscribe(\n        'projects/<my_project>/subscriptions/<my_subscription>',\n        handler,\n        subscriber_client,\n        num_producers=1,\n        max_messages_per_producer=100,\n        ack_window=0.3,\n        num_tasks_per_consumer=1,\n        enable_nack=True,\n        nack_window=0.3,\n    )\n\nWhile defaults are somewhat sensible, it is highly recommended to performance\ntest your application and tweak function parameter to your specific needs.\nHere's a few hints:\n\n:``handler``:\n    an async function that will be called for each message. It should accept an\n    instance of ``SubscriberMessage`` as its only argument and return ``None``\n    if the message should be acked. An exception raised within the handler will\n    result in the message being left to expire, and thus it will be redelivered\n    according to your subscription's ack deadline.\n\n:``num_producers``:\n    number of workers that will be making ``pull`` requests to pubsub. Please\n    note that a worker will only fetch new batch once the ``handler`` was called\n    for each message from the previous batch. This means that running only a\n    single worker will most likely make your application IO bound. If you notice\n    this being an issue don't hesitate to bump this parameter.\n\n:``max_messages_per_producer``:\n    number of pubsub messages a worker will try to fetch in a single batch. This\n    value is passed to ``pull`` `endpoint`_ as ``maxMessages`` parameter. A rule\n    of thumb here is the faster your handler is the bigger this value should be.\n\n:``ack_window``:\n    ack requests are handled separately and are done in batches. This parameters\n    specifies how often ack requests will be made. Setting it to ``0.0`` will\n    effectively disable batching.\n\n:``num_tasks_per_consumer``:\n    how many ``handle`` calls a worker can make until it blocks to wait for them\n    to return. If you process messages independently from each other you should\n    be good with the default value of ``1``. If you do something fancy (e.g.\n    aggregate messages before processing them), you'll want a higher pool here.\n    You can think of ``num_producers * num_tasks_per_consumer`` as an upper\n    limit of how many messages can possibly be within your application state at\n    any given moment.\n\n:``enable_nack``:\n    if enabled messages for which ``callback`` raised an exception will be\n    explicitly nacked using ``modifyAckDeadline`` endpoint so they can be\n    retried immediately.\n\n:``nack_window``:\n    same as ``ack_window`` but for nack requests\n\n\nPrometheus Metrics\n^^^^^^^^^^^^^^^^^^\n\nIf you like pull-based metrics like Prometheus you will be pleased to know that\nthe subscriber records Prometheus metrics in the form\n``gcloud_rest_pubsub_<metric>``, which will have no effect if you don't use\nPrometheus to scrape app metrics:\n\n- ``subscriber_batch_size`` - [histogram] how many messages were pulled from\n  the subscription in a single batch\n- ``subscriber_consume`` (labels: ``outcome = {'succeeded', 'cancelled',\n  'failed', 'failfast'}``) - [counter] a consume operation has completed with a\n  given outcome\n- ``subscriber_consume_latency_seconds`` (labels: ``phase = {'receive',\n  'queueing', 'runtime'}``) - [histogram] how many seconds taken to receive a\n  message, while waiting for processing, or to complete the callback\n- ``subscriber_batch_status`` (labels: ``component = {'acker', 'nacker'},\n  outcome = {'succeeded', 'failed'}``) - [counter] a batch has succeeded or\n  failed to be acked or nacked\n- ``subscriber_messages_processed`` (labels: ``component = {'acker',\n  'nacker'}``) - [counter] the number of messages that were processed, either\n  by being acked or nacked\n- ``subscriber_messages_received`` - [counter] the number of messages\n  pulled from pubsub\n\n\nMetrics Agent (Deprecated)\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``subscribe`` has also an optional ``metrics_client`` argument which will be\nremoved in a future release. You can provide any metrics agent that implements\nthe same interface as ``MetricsAgent`` (Datadog client will do ;) ) and get the\nfollowing metrics:\n\n- ``pubsub.producer.batch`` - [histogram] actual size of a batch retrieved from\n  pubsub.\n\n- ``pubsub.consumer.failfast`` - [increment] a message was dropped due to its\n  lease being expired.\n\n- ``pubsub.consumer.latency.receive`` - [histogram] how many seconds it took for\n  a message to reach handler after it was published.\n\n- ``pubsub.consumer.succeeded`` - [increment] ``handler`` call was successfull.\n\n- ``pubsub.consumer.failed`` - [increment] ``handler`` call raised an exception.\n\n- ``pubsub.consumer.latency.runtime`` - [histogram] ``handler`` execution time\n  in seconds.\n\n- ``pubsub.acker.batch.failed`` - [increment] ack request failed.\n\n- ``pubsub.acker.batch`` - [histogram] actual number of messages that was acked\n  in a single request.\n\n\nPublisher\n~~~~~~~~~\n\nThe ``PublisherClient`` is a dead-simple alternative to the official Google\nCloud Pub/Sub publisher client. The main design goal was to eliminate all the\nadditional gRPC overhead implemented by the upstream client.\n\nIf migrating between this library and the official one, the main difference is\nthis: the ``gcloud-{aio,rest}-pubsub`` publisher's ``.publish()`` method *immediately*\npublishes the messages you've provided, rather than maintaining our own\npublishing queue, implementing batching and flow control, etc. If you're\nlooking for a full-featured publishing library with all the bells and whistles\nbuilt in, you may be interested in the upstream provider. If you're looking to\nmanage your own batching / timeouts / retry / threads / etc, this library\nshould be a bit easier to work with.\n\nSample usage:\n\n.. code-block:: python\n\n    from gcloud.rest.pubsub import PubsubMessage\n    from gcloud.rest.pubsub import PublisherClient\n\n    async with aiohttp.ClientSession() as session:\n        client = PublisherClient(session=session)\n\n        topic = client.topic_path('my-gcp-project', 'my-topic-name')\n\n        messages = [\n            PubsubMessage(b'payload', attribute='value'),\n            PubsubMessage(b'other payload', other_attribute='whatever',\n                          more_attributes='something else'),\n        ]\n        response = await client.publish(topic, messages)\n        # response == {'messageIds': ['1', '2']}\n\nEmulators\n^^^^^^^^^\n\nFor testing purposes, you may want to use ``gcloud-rest-pubsub`` along with a\nlocal GCS emulator. Setting the ``$PUBSUB_EMULATOR_HOST`` environment variable\nto the local address of your emulator should be enough to do the trick.\n\nFor example, using the official Google Pubsub emulator:\n\n.. code-block:: console\n\n    gcloud beta emulators pubsub start --host-port=0.0.0.0:8681\n    export PUBSUB_EMULATOR_HOST='0.0.0.0:8681'\n\nAny ``gcloud-rest-pubsub`` Publisher requests made with that environment\nvariable set will query the emulator instead of the official GCS APIs.\n\nFor easier ergonomics, you may be interested in\n`messagebird/gcloud-pubsub-emulator`_.\n\nCustomization\n-------------\n\nThis library mostly tries to stay agnostic of potential use-cases; as such, we\ndo not implement any sort of retrying or other policies under the assumption\nthat we wouldn't get things right for every user's situation.\n\nAs such, we recommend configuring your own policies on an as-needed basis. The\n`backoff`_ library can make this quite straightforward! For example, you may\nfind it useful to configure something like:\n\n.. code-block:: python\n\n    class SubscriberClientWithBackoff(SubscriberClient):\n        @backoff.on_exception(backoff.expo, aiohttp.ClientResponseError,\n                              max_tries=5, jitter=backoff.full_jitter)\n        async def pull(self, *args: Any, **kwargs: Any):\n            return await super().pull(*args, **kwargs)\n\nContributing\n------------\n\nPlease see our `contributing guide`_.\n\n.. _contributing guide: https://github.com/talkiq/gcloud-rest/blob/master/.github/CONTRIBUTING.rst\n.. _messagebird/gcloud-pubsub-emulator: https://github.com/marcelcorso/gcloud-pubsub-emulator#gcloud-pubsub-emulator\n.. _official Google documentation: https://github.com/googleapis/google-cloud-python/blob/11c72ade8b282ae1917fba19e7f4e0fe7176d12b/pubsub/google/cloud/pubsub_v1/gapic/subscriber_client.py#L236\n.. _backoff: https://pypi.org/project/backoff/\n\n.. |pypi| image:: https://img.shields.io/pypi/v/gcloud-rest-pubsub.svg?style=flat-square\n    :alt: Latest PyPI Version\n    :target: https://pypi.org/project/gcloud-rest-pubsub/\n\n.. |pythons-aio| image:: https://img.shields.io/pypi/pyversions/gcloud-rest-pubsub.svg?style=flat-square&label=python (aio)\n    :alt: Python Version Support (gcloud-rest-pubsub)\n    :target: https://pypi.org/project/gcloud-rest-pubsub/\n\n.. |pythons-rest| image:: https://img.shields.io/pypi/pyversions/gcloud-rest-pubsub.svg?style=flat-square&label=python (rest)\n    :alt: Python Version Support (gcloud-rest-pubsub)\n    :target: https://pypi.org/project/gcloud-rest-pubsub/\n\n.. _endpoint: https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions/pull#request-body\n",
    'author': 'Vi Engineering',
    'author_email': 'voiceai-eng@dialpad.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/talkiq/gcloud-aio',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*',
}


setup(**setup_kwargs)

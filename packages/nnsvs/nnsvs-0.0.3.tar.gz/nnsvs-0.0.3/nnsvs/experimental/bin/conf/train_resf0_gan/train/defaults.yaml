out_dir: exp
log_dir: tensorboard/exp

# steps can either be specified by steps or epochs
max_train_steps: -1
nepochs: 50
checkpoint_epoch_interval: 20

# mse (mean squared error; l2 loss) or mae (mean absolute error; l1 loss)
# NOTE: no effect for MDN models
feats_criterion: mse

# Weight for pitch regularization loss
# If > 0.0, add a pitch regularization loss that biases the model to
# predict closer F0 to the F0 derived from the musical score.
# This is conceptually same as imposing a prior distribution of the residual F0
# to be N(0, sigma) (if we use L2 loss)
# https://arxiv.org/abs/2108.02776
pitch_reg_weight: 1.0

# GAN type (lsgan or vanilla-gan)
gan_type: vanilla-gan
# Adverdarial loss weight
adv_weight: 0.25
# [mgc, lf0, vuv, bap, vib, vib_flags]
adv_streams: [True, False, False, False, False, False]
# Use static features as the input of the discriminator or not
adv_use_static_feats_only: true
# Feature matching loss weight
fm_weight: 0.1
# Don't set the value > 0 unless you are sure what you are doing
# mask 0 to n-th mgc for adversarial loss
# e.g, for n=2, 0-th and 1-th mgc coefficients will be masked
mask_nth_mgc_for_adv_loss: 2

stream_wise_loss: false
use_detect_anomaly: true

# Use automatic mixed precision training or not
# only works on supported GPUs
use_amp: false

optim:
  netG:
    optimizer:
      name: Adam
      params:
        lr: 0.001
        betas: [0.9, 0.999]
        weight_decay: 0.0
    lr_scheduler:
      name: StepLR
      params:
        step_size: 20
        gamma: 0.5
    clip_norm: 1.0
  netD:
    optimizer:
      name: Adam
      params:
        lr: 0.001
        betas: [0.9, 0.999]
        weight_decay: 0.0
    lr_scheduler:
      name: StepLR
      params:
        step_size: 20
        gamma: 0.5
    clip_norm: 1.0

resume:
  netG:
    checkpoint:
    load_optimizer: false
  netD:
    checkpoint:
    load_optimizer: false

cudnn:
  benchmark: false
  deterministic: true

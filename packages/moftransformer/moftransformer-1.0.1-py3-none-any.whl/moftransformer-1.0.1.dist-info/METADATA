Metadata-Version: 2.1
Name: moftransformer
Version: 1.0.1
Summary: moftransformer
Home-page: https://hspark1212.github.io/MOFTransformer/
Download-URL: https://github.com/hspark1212/MOFTransformer
Author: Yeonghun Kang, Hyunsoo Park
Author-email: dudgns1675@kaist.ac.kr, phs68660888@gmail.com
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: wget
Requires-Dist: pytorch-lightning (>=1.6.0)
Requires-Dist: torch (>=1.10.0)
Requires-Dist: torchmetrics (>=0.6.0)
Requires-Dist: transformers (>=4.12.5)
Requires-Dist: timm (>=0.4.12)
Requires-Dist: sacred (>=0.8.2)
Requires-Dist: einops (>=0.4.1)
Requires-Dist: ase (>=3.22.1)
Requires-Dist: pymatgen (>=2022.0.16)
Requires-Dist: matplotlib (>=3.5.0)
Requires-Dist: seaborn (>=0.12.0)
Requires-Dist: ipympl (>=0.9.2)
Requires-Dist: pandas
Requires-Dist: tqdm
Requires-Dist: google-auth
Requires-Dist: jupyter-client
Requires-Dist: smmap (<6)
Requires-Dist: emmet-core
Requires-Dist: numpy (~=1.22.3)
Provides-Extra: docs
Requires-Dist: sphinx ; extra == 'docs'
Requires-Dist: livereload ; extra == 'docs'
Requires-Dist: myst-parser ; extra == 'docs'

# MOFTransformer

 Do you train machine learning models for every application? This package provides universal transfer learing for metal-organic frameworks(MOFs) to construct structure-property relationships. `MOFTransformer` obtains state-of-the-art performance to predict accross various properties that include gas adsorption, diffusion, electronic properties regardless of gas types. Beyond its universal transfer learning capabilityies, it provides feature importance analysis from its attentions scores to capture chemical intution.
<p align="center">
  <img src="https://github.com/hspark1212/MOFTransformer/blob/master/docs/source/assets/fig1.jpg" width=800>
</p>

## Architectures
`MOFTransformer`is a multi-modal Transformer pre-trained with 1 million hypothetical MOFs so that it efficiently capture both local and global feeatures of MOFs.

- `MOFformer` takes two different representations as input
  - Atom-based Graph Embedding : CGCNN w/o pooling layer -> local features
  - Energy-grid Embedding : 1D flatten patches of 3D energy grid -> global features
<p align="center">
  <img src="https://github.com/hspark1212/MOFTransformer/blob/master/docs/source/assets/fig2.jpg" width=800>
</p>

## Install

## Getting Started

## Feature Importance Anaylsis
you can easily visualize feature importance analysis of atom-based graph embeddings and energy-grid embeddings.
```python
%matplotlib widget
from visualize import PatchVisualizer

model_path = "examples/finetuned_bandgap.ckpt" # or 'examples/finetuned_h2_uptake.ckpt'
data_path = 'examples/visualize/dataset/'
cifname = 'MIBQAR01_FSR'

vis = PatchVisualizer.from_cifname(cifname, model_path, data_path)
vis.draw_graph()
```
<img src="https://github.com/hspark1212/MOFTransformer/blob/master/docs/source/getting_started/assets/1.gif" width="300">

```python
vis = PatchVisualizer.from_cifname(cifname, model_path, data_path)
vis.draw_grid()
```
<img src="https://github.com/hspark1212/MOFTransformer/blob/master/docs/source/getting_started/assets/3.gif" width="300">

## Universal Transfer Learning
| Property                                 | MOFTransformer | Original Paper | Number of Data | Remarks          | Reference |
|------------------------------------------|----------------|----------------|----------------|------------------|-----------|
|N<sub>2</sub> uptake                     | R2: 0.78       | R2: 0.71       | 5,286          | CoRE MOF         | 1         |
|O<sub>2</sub> uptake                     | R2: 0.83       | R2: 0.74       | 5,286          | CoRE MOF         | 1         |
|N<sub>2</sub> diffusivity                | R2: 0.77       | R2: 0.76       | 5,286          | CoRE MOF         | 1         |
|O<sub>2</sub> diffusivity                | R2: 0.78       | R2: 0.74       | 5,286          | CoRE MOF         | 1         |
|CO<sub>2</sub> Henry coefficient         | MAE : 0.30     | MAE : 0.42     | 8,183          | CoRE MOF         | 2         |
|Solvent removal stability classification | ACC : 0.76     | ACC : 0.76     | 2,148          | Text-mining data | 3         |
|Thermal stability regression             | R2 : 0.44      | R2 : 0.46      | 3,098          | Text-mining data | 3         |
### reference
1. [Prediction of O2/N2 Selectivity in Metal−Organic Frameworks via High-Throughput Computational Screening and Machine Learning](https://pubs.acs.org/doi/abs/10.1021/acsami.1c18521)
2. [Using Machine Learning and Data Mining to Leverage Community Knowledge for the Engineering of Stable Metal–Organic Frameworks](https://pubs.acs.org/doi/10.1021/jacs.1c07217)
3. [Understanding the diversity of the metal-organic framework ecosystem](https://www.nature.com/articles/s41467-020-17755-8)
